import torch
import triton
import triton.language as tl

# ----------------------------------------
# Triton kernelï¼šæ¯ä¸ª block å¯¹ä¸€æ®µæ•°æ®å½’çº¦æ±‚å’Œ
@triton.jit
def blockwise_sum_kernel(X, partial_sums, N, BLOCK_SIZE: tl.constexpr):
    # èŽ·å–å½“å‰ block çš„ IDï¼ˆç±»ä¼¼ CUDA ä¸­ blockIdx.xï¼‰
    pid = tl.program_id(0)

    # å½“å‰ block è¦å¤„ç†çš„ä¸€æ®µå…¨å±€ç´¢å¼•
    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)

    # åˆ›å»º maskï¼šå±è”½æŽ‰è¶Šç•Œç´¢å¼•ï¼ˆoffset >= Nï¼‰
    mask = offsets < N

    # å®‰å…¨åŠ è½½æ•°æ®ï¼ˆè¶Šç•Œéƒ¨åˆ†ä¸ä¼šè¯»ï¼‰
    x = tl.load(X + offsets, mask=mask)

    # æ¯ä¸ª block å†…éƒ¨è¿›è¡Œå½’çº¦ï¼šå°† BLOCK_SIZE ä¸ªå…ƒç´ æ±‚å’Œ
    # è¿™é‡Œä½¿ç”¨ tl.sumï¼ˆé»˜è®¤ float32 ç²¾åº¦ï¼‰ï¼Œè‡ªåŠ¨å¹¶è¡Œå¤„ç†
    acc = tl.sum(x, axis=0)

    # å°†å½“å‰ block çš„æ±‚å’Œç»“æžœå†™å…¥ partial_sums[pid]
    tl.store(partial_sums + pid, acc)

# ----------------------------------------
# Python ä¸»ç¨‹åºéƒ¨åˆ†

# â— å®žéªŒåŽŸç†ï¼š
# æœ¬å®žéªŒç›®çš„æ˜¯éªŒè¯ï¼šä½¿ç”¨ Triton è¿›è¡Œåˆ†å—å¹¶è¡Œå½’çº¦æ±‚å’Œï¼Œä¸Ž PyTorch å†…ç½® sum() çš„æ•°å€¼ç²¾åº¦å·®å¼‚ã€‚
# æˆ‘ä»¬å°†ä¸€ä¸ªå¤§æ•°ç»„ x æ‹†åˆ†æˆå¤šä¸ª blockï¼Œåœ¨æ¯ä¸ª block å†…ç‹¬ç«‹å®Œæˆæ±‚å’Œï¼Œå¹¶æœ€ç»ˆç”¨ CPU æ±‡æ€»ã€‚
# ç”±äºŽæµ®ç‚¹æ•°çš„åŠ æ³•é¡ºåºä¸åŒï¼ˆå³ä½¿æ•°å­¦ä¸Š a + b + c = c + a + bï¼‰ï¼Œåœ¨ float32 ç²¾åº¦ä¸‹è¯¯å·®å¯èƒ½å‡ºçŽ°ã€‚
# æ‰€ä»¥æˆ‘ä»¬ä¹Ÿç‰¹æ„å°†å€¼ä¹˜ä»¥ 1e3 æ¥æ”¾å¤§è¯¯å·®ï¼Œè®©ä½ èƒ½çœ‹åˆ°ä¸¤ä¸ªå®žçŽ°ä¹‹é—´å¾®å°çš„è¯¯å·®å·®å¼‚ã€‚

# å‘é‡é•¿åº¦
N = 1000  # å¯ä»¥å¢žå¤§ä¸º 1_000_000 ä»¥æ”¾å¤§è¯¯å·®çŽ°è±¡

# æ¯ä¸ª block å¤„ç†çš„æ•°æ®é‡
BLOCK_SIZE = 256

# æ€»å…±éœ€è¦å‡ ä¸ª blockï¼ˆå‘ä¸Šå–æ•´ï¼‰
NUM_BLOCKS = triton.cdiv(N, BLOCK_SIZE)

# åˆ›å»ºè¾“å…¥æ•°æ®ï¼ˆå€¼ä¹˜ä»¥ 1e3 æ”¾å¤§è¯¯å·®å½±å“ï¼‰
x = torch.rand(N, device='cuda', dtype=torch.float32) * 1e3

# partial_sums ä¿å­˜æ¯ä¸ª block çš„å±€éƒ¨å’Œ
partial_sums = torch.empty(NUM_BLOCKS, device='cuda', dtype=torch.float32)

# å¯åŠ¨ Triton kernelï¼ˆNUM_BLOCKS ä¸ªå¹¶è¡Œç¨‹åºå—ï¼‰
blockwise_sum_kernel[(NUM_BLOCKS,)](
    x, partial_sums, N,
    BLOCK_SIZE=BLOCK_SIZE
)

# Triton çš„æœ€ç»ˆæ±‚å’Œç»“æžœï¼šæŠŠæ‰€æœ‰å±€éƒ¨å’ŒåŠ èµ·æ¥
total_sum = partial_sums.sum().item()

# PyTorch çš„çœŸå®žå‚è€ƒå€¼ï¼ˆå•æ¬¡é«˜ç²¾åº¦æ±‚å’Œï¼‰
torch_sum = x.sum().item()

# è®¡ç®—ç»å¯¹è¯¯å·®
error = abs(total_sum - torch_sum)

# æ‰“å°ç»“æžœ
print(f"âœ… Triton æ€»å’Œï¼š   {total_sum:.6f}")
print(f"âœ… PyTorch æ€»å’Œï¼š {torch_sum:.6f}")
print(f"ðŸŽ¯ è¯¯å·®ï¼š           {error:.6e}")
